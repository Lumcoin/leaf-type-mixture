{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "Preprocess and unify all data.\n",
    "\n",
    "Before starting to train a ML model, we have to preprocess our data. In this case Sentinel-2 Level-2A imagery is used to generate composites by maximum NDVI across a period of two months. The resulting composites are augmented with indices, like NDVI and all timesteps are reduced into a single raster by deriving statistical parameters, like mean and variance.\n",
    "\n",
    "The DEM image uploaded beforehand is downsampled to the same resolution as the Sentinel-2 composites by calculating various textile measures.\n",
    "\n",
    "Then the resulting Sentinel-2 derived raster and DEM derived raster are stacked and a dimensionality reduction is performed. The reduced image can then be used for further processing.\n",
    "\n",
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Earth Engine API and initialize it\n",
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "# Define data constants\n",
    "SOURCE = 'COPERNICUS/S2_HARMONIZED'  # Define dataset source\n",
    "REGION = ee.Geometry.Rectangle([12.6545, 47.9291, 12.6762, 47.9423])  # Define region in EPSG:4326\n",
    "\n",
    "# Define processing constants\n",
    "TIMESERIES_MIDDLE = '2016-01-01'  # Define middle of timeseries\n",
    "TIMESERIES_DURATION = 365  # Define duration of timeseries in days\n",
    "NUM_COMPOSITES = 12  # Define amount of composites in the timeseries\n",
    "TEMPORAL_REDUCERS = [ee.Reducer.median(), ee.Reducer.variance(), ee.Reducer.mean(), ee.Reducer.skew()]  # Define temporal reducer\n",
    "\n",
    "# Define quality measure for composites\n",
    "def addQuality(image):\n",
    "    quality_band = image.normalizedDifference(['B5', 'B4']).rename(['quality'])  # NDVI in this case\n",
    "    return image.addBands(quality_band)\n",
    "\n",
    "# Define export constants\n",
    "FILENAME = 'NDVI_composite'  # Name of exported raster\n",
    "FOLDER = 'Google Earth Engine'  # Name of export folder\n",
    "SCALE = 10  # Size of pixel in meters\n",
    "CRS = 'EPSG:32632'  # Coordinate reference system of exported raster\n",
    "MAX_PIXELS = 1e7  # Maximum number of pixels when exporting\n",
    "\n",
    "# Define map constants\n",
    "VIS_PARAMS = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.2, 'gamma': 1}\n",
    "LAYER_NAME = FILENAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Timeseries Windows for calculating Composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2015-07-02', '2015-08-01'), ('2015-08-01', '2015-09-01'), ('2015-09-01', '2015-10-01'), ('2015-10-01', '2015-11-01'), ('2015-11-01', '2015-12-01'), ('2015-12-01', '2016-01-01'), ('2016-01-01', '2016-01-31'), ('2016-01-31', '2016-03-01'), ('2016-03-01', '2016-04-01'), ('2016-04-01', '2016-05-01'), ('2016-05-01', '2016-06-01'), ('2016-06-01', '2016-07-01')]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_timewindows(middle_date, num_windows, timeseries_duration=365.242):\n",
    "    # Calculate the start date of the timeseries\n",
    "    middle_date = datetime.strptime(middle_date, '%Y-%m-%d')\n",
    "    current_start = middle_date - timedelta(days=timeseries_duration / 2)\n",
    "\n",
    "    # Calculate the duration of each timewindow (in days)\n",
    "    window_duration = timeseries_duration / num_windows\n",
    "    \n",
    "    # Initialize a list to store the timewindows as tuples\n",
    "    timewindows = []\n",
    "    for _ in range(num_windows):\n",
    "        # Calculate the start and end dates of each timewindow\n",
    "        start_date = current_start\n",
    "        end_date = current_start + timedelta(days=window_duration)\n",
    "\n",
    "        start_date = start_date.strftime('%Y-%m-%d')\n",
    "        end_date = end_date.strftime('%Y-%m-%d')\n",
    "        timewindow = (start_date, end_date)\n",
    "        \n",
    "        # Append the timewindow as a tuple (start, end) to the list\n",
    "        timewindows.append(timewindow)\n",
    "        \n",
    "        # Move the middle_date to the next timewindow\n",
    "        current_start += timedelta(days=window_duration)\n",
    "    \n",
    "    return timewindows\n",
    "\n",
    "timewindows = generate_timewindows(TIMESERIES_MIDDLE, NUM_COMPOSITES, TIMESERIES_DURATION)\n",
    "print(timewindows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Sentinel-2 Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskS2clouds(image, cld_thresh=0.8, snw_thresh=0.8):\n",
    "  # -----------------------------------------------------------------------\n",
    "  qa = image.select('QA60')\n",
    "\n",
    "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "  cloudBitMask = 1 << 10\n",
    "  cirrusBitMask = 1 << 11\n",
    "\n",
    "  # Both flags should be set to zero, indicating clear conditions.\n",
    "  mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "  # -----------------------------------------------------------------------\n",
    "\n",
    "  # Use MSK_CLDPRB and MSK_SNWPRB Level 2A bands with a threshold of 100\n",
    "  # cld_prb = image.select('MSK_CLDPRB').divide(100)\n",
    "  # snw_prb = image.select('MSK_SNWPRB').divide(100)\n",
    "  # mask = cld_prb.lt(cld_thresh).And(snw_prb.lt(snw_thresh))\n",
    "\n",
    "  return image.updateMask(mask).divide(10000)\n",
    "\n",
    "def get_bands(image, print=False):\n",
    "  bands = [band['id'] for band in image.getInfo()['bands']]\n",
    "\n",
    "  if print:\n",
    "    print(bands)\n",
    "\n",
    "  return bands\n",
    "\n",
    "def get_reducer_name(reducer, print=False):\n",
    "  reducer_name = reducer.getInfo()['type'].split('.')[-1]\n",
    "\n",
    "  if print:\n",
    "    print(reducer_name)\n",
    "\n",
    "  return reducer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define methods for calculating indices\n",
    "def add_ndvi(image):\n",
    "    ndvi_band = image.normalizedDifference(['B5', 'B4']).rename(['NDVI'])\n",
    "    return image.addBands(ndvi_band)\n",
    "\n",
    "def add_ndwi(image):\n",
    "    ndwi_band = image.normalizedDifference(['B3', 'B5']).rename(['NDWI'])\n",
    "    return image.addBands(ndwi_band)\n",
    "\n",
    "add_indices = [add_ndvi, add_ndwi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked images: ['0_B1_median', '0_B2_median', '0_B3_median', '0_B4_median', '0_B5_median', '0_B6_median', '0_B7_median', '0_B8_median', '0_B8A_median', '0_B9_median', '0_B10_median', '0_B11_median', '0_B12_median', '0_NDVI_median', '0_NDWI_median', '1_B1_variance', '1_B2_variance', '1_B3_variance', '1_B4_variance', '1_B5_variance', '1_B6_variance', '1_B7_variance', '1_B8_variance', '1_B8A_variance', '1_B9_variance', '1_B10_variance', '1_B11_variance', '1_B12_variance', '1_NDVI_variance', '1_NDWI_variance', '2_B1_mean', '2_B2_mean', '2_B3_mean', '2_B4_mean', '2_B5_mean', '2_B6_mean', '2_B7_mean', '2_B8_mean', '2_B8A_mean', '2_B9_mean', '2_B10_mean', '2_B11_mean', '2_B12_mean', '2_NDVI_mean', '2_NDWI_mean', '3_B1_skew', '3_B2_skew', '3_B3_skew', '3_B4_skew', '3_B5_skew', '3_B6_skew', '3_B7_skew', '3_B8_skew', '3_B8A_skew', '3_B9_skew', '3_B10_skew', '3_B11_skew', '3_B12_skew', '3_NDVI_skew', '3_NDWI_skew']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/v1/projects/earthengine-legacy/thumbnails/624224564d8d01ed15987fb7617186b6-06b38ab1ac154fee26dfea13732e6a7f:getPixels\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import eemont\n",
    "\n",
    "composites = []\n",
    "for start, end in timewindows:\n",
    "    # Define dataset filters\n",
    "    filter_date = ee.Filter.date(start, end)  # inclusive start, exclusive end\n",
    "    filter_region = ee.Filter.bounds(REGION)\n",
    "\n",
    "    # Read dataset\n",
    "    dataset = ee.ImageCollection(SOURCE).filter(filter_date).filter(filter_region).map(maskS2clouds)\n",
    "\n",
    "    # Remove QA bands\n",
    "    remaining_bands = dataset.first().bandNames().getInfo()\n",
    "    remaining_bands = [band for band in remaining_bands if not band.startswith('QA')]\n",
    "    dataset = dataset.select(remaining_bands)\n",
    "\n",
    "    dataset = dataset.spectralIndices(['NDVI','NDWI'])\n",
    "\n",
    "    # Create max NDVI pixel composite\n",
    "    dataset = dataset.map(addQuality)  # Add quality band\n",
    "    composite = dataset.qualityMosaic('quality')  # Choose max quality pixels\n",
    "\n",
    "    # Remove quality band\n",
    "    remaining_bands = composite.bandNames().getInfo()\n",
    "    remaining_bands.remove('quality')\n",
    "    composite = composite.select(remaining_bands)  # Remove quality band\n",
    "\n",
    "    # Add to time series\n",
    "    composites.append(composite)\n",
    "\n",
    "# Create image collection\n",
    "composites = ee.ImageCollection(composites)\n",
    "\n",
    "# Apply remporal reducers to image collection\n",
    "if TEMPORAL_REDUCERS == []:\n",
    "    reduced_images = [composites.toBands()]  # TODO\n",
    "else:\n",
    "    reduced_images = [composites.reduce(temporal_reducer) for temporal_reducer in TEMPORAL_REDUCERS]\n",
    "\n",
    "# Stack images\n",
    "stacked_images = ee.ImageCollection(reduced_images).toBands()\n",
    "stacked_images = stacked_images.reproject(crs=CRS, scale=SCALE)\n",
    "stacked_images = stacked_images.clip(REGION)\n",
    "\n",
    "# Define RGB bands\n",
    "rgb_bands = get_bands(stacked_images)[3:0:-1]\n",
    "\n",
    "print('Stacked images:', stacked_images.bandNames().getInfo())\n",
    "\n",
    "# Show image\n",
    "Image(url=stacked_images.getThumbUrl({\n",
    "    **VIS_PARAMS,\n",
    "    'bands': rgb_bands,\n",
    "    'dimensions': 500}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b1', 'b1_mean', 'b1_variance', 'b1_asm', 'b1_contrast', 'b1_corr', 'b1_var', 'b1_idm', 'b1_savg', 'b1_svar', 'b1_sent', 'b1_ent', 'b1_dvar', 'b1_dent', 'b1_imcorr1', 'b1_imcorr2', 'b1_maxcorr', 'b1_diss', 'b1_inertia', 'b1_shade', 'b1_prom']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/v1/projects/earthengine-legacy/thumbnails/37e93ae259e84cc28a78177352ead9ba-f2b2af9cfa4b81f249211da58e588225:getPixels\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Load the DEM\n",
    "dem = ee.Image('projects/leaf-type-mixture/assets/DEM')\n",
    "band_name = dem.bandNames().getInfo()[0]\n",
    "\n",
    "# Calculate textile measures\n",
    "dem_mean = dem.reduceResolution(ee.Reducer.mean(), maxPixels=1024).rename(band_name + '_mean')\n",
    "dem_variance = dem.reduceResolution(ee.Reducer.variance(), maxPixels=1024).rename(band_name + '_variance')\n",
    "dem_glcm = dem.multiply(1000).toUint16().glcmTexture()  # naive approach to avoid memory issues\n",
    "\n",
    "# Stack the DEM and its gradient\n",
    "dem = dem.addBands([dem_mean, dem_variance, dem_glcm])\n",
    "\n",
    "# Clip to the region of interest\n",
    "dem = dem.reproject(crs=CRS, scale=SCALE)\n",
    "dem = dem.clip(REGION)\n",
    "\n",
    "# Print all bands\n",
    "print(dem.bandNames().getInfo())\n",
    "\n",
    "Image(url=dem.getThumbUrl({\n",
    "    'min': -5,\n",
    "    'max': 50,\n",
    "    'bands': ['b1_shade', 'b1_diss', 'b1_prom'],\n",
    "    'region': REGION,\n",
    "    'dimensions': 500}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rasterize Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/v1/projects/earthengine-legacy/thumbnails/7dd22aad9e10ff5fb2f4a6b6f9c5d4e3-42bfb331c45390b865a3d69cf2fe135f:getPixels\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants, zero for conifers, one for broadleafs\n",
    "CONIFER = 0\n",
    "BROADLEAF = 1\n",
    "\n",
    "# Map leaf type to a number\n",
    "leaf_type_dict = {'Abies alba': CONIFER,\n",
    "                  'Acer campestre': BROADLEAF,\n",
    "                  'Acer platanoides': BROADLEAF,\n",
    "                  'Acer pseudoplatanus': BROADLEAF,   \n",
    "                  'Aesculus hippocastanum': BROADLEAF,\n",
    "                  'Alnus glutinose': BROADLEAF,\n",
    "                  'Betula ': BROADLEAF,\n",
    "                  'Carpinus betulus': BROADLEAF,\n",
    "                  'Fagus sylvatica': BROADLEAF,\n",
    "                  'Fraxinus excelsior': BROADLEAF,\n",
    "                  'Juglans regia': BROADLEAF,\n",
    "                  'Larix decidua': CONIFER,\n",
    "                  'Picea abies': CONIFER,\n",
    "                  'Pinus sylvestris': CONIFER,\n",
    "                  'Populus ': BROADLEAF,\n",
    "                  'Populus tremula': BROADLEAF,\n",
    "                  'Prunus avium': BROADLEAF,\n",
    "                  'Pseudotsuga menziesii': CONIFER,\n",
    "                  'Quercus ': BROADLEAF,\n",
    "                  'Quercus rubra': BROADLEAF,\n",
    "                  'Salix ': BROADLEAF,\n",
    "                  'Sorbus aria': BROADLEAF,\n",
    "                  'Sorbus aucuparia': BROADLEAF,\n",
    "                  'Sorbus torminalis': BROADLEAF,\n",
    "                  'Thuja plicata': CONIFER,\n",
    "                  'Tilia ': BROADLEAF,\n",
    "                  'Ulmus glabra': BROADLEAF,\n",
    "                  'Unidentified broadleaf': BROADLEAF,\n",
    "                  'Unidentified conifer': CONIFER}\n",
    "\n",
    "# Read in the plot data\n",
    "df = gpd.read_file('../data/raw/Plot.gpkg').to_crs('EPSG:4326')\n",
    "\n",
    "# Create Longitude, Latitude, and Broadleaf columns\n",
    "df['Longitude'] = df['geometry'].x\n",
    "df['Latitude'] = df['geometry'].y\n",
    "df['Species'] = df['Latin'] + ' ' + df['Mnemonic']\n",
    "df['Broadleaf'] = df['Species'].map(leaf_type_dict)\n",
    "\n",
    "# Keep only the columns we need\n",
    "df = df[['Longitude', 'Latitude', 'Broadleaf']]\n",
    "\n",
    "# Convert pandas DataFrame to Earth Engine FeatureCollection\n",
    "fc = ee.FeatureCollection([ee.Feature(ee.Geometry.Point([row['Longitude'], row['Latitude']]), {'Broadleaf': row['Broadleaf']}) for index, row in df.iterrows()])\n",
    "\n",
    "# Rasterize the FeatureCollection using reduceToImage\n",
    "plot = fc.reduceToImage(['Broadleaf'], ee.Reducer.mean())\n",
    "plot = plot.reproject(crs=CRS, scale=SCALE)\n",
    "plot = plot.clip(REGION)\n",
    "\n",
    "# Color palette\n",
    "viridis_cmap = plt.get_cmap('viridis')\n",
    "colors = []\n",
    "for i in range(256):\n",
    "    r, g, b, a = (int(value * 255) for value in viridis_cmap(i))\n",
    "    colors.append(f'#{r:02X}{g:02X}{b:02X}')\n",
    "\n",
    "Image(url=plot.getThumbUrl({\n",
    "    'min': 0,\n",
    "    'max': 1,\n",
    "    'palette': colors,\n",
    "    'region': REGION,\n",
    "    'dimensions': 500}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save (& fuse DEM with Time Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image downloaded and saved successfully!\n",
      "Image downloaded and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import rasterio\n",
    "from rasterio.io import MemoryFile\n",
    "import numpy as np\n",
    "\n",
    "def download_image(image, scale, crs):\n",
    "    download_params = {\n",
    "        'scale': scale,\n",
    "        'crs': crs,\n",
    "        'format': 'GEO_TIFF',\n",
    "    }\n",
    "    url = image.getDownloadURL(download_params)\n",
    "\n",
    "    return requests.get(url)\n",
    "\n",
    "def save_image_to_file(image, file_path, mask, bands):\n",
    "    with MemoryFile(image) as memfile, MemoryFile(mask) as mask_memfile:\n",
    "        with memfile.open() as dataset, mask_memfile.open() as mask_dataset:\n",
    "            profile = dataset.profile\n",
    "            with rasterio.open(file_path, 'w', **profile) as dst:\n",
    "                raster = dataset.read()\n",
    "                mask = mask_dataset.read()\n",
    "                raster[mask == 0] = np.nan\n",
    "                dst.write(raster)\n",
    "                dst.descriptions = tuple(bands)\n",
    "\n",
    "def save_image(image, file_path, scale, crs):\n",
    "    image_response = download_image(image, scale, crs)\n",
    "    mask_response = download_image(image.mask(), scale, crs)\n",
    "    \n",
    "    if image_response.status_code == mask_response.status_code == 200:\n",
    "        save_image_to_file(image_response.content,\n",
    "                           file_path,\n",
    "                           mask=mask_response.content,\n",
    "                           bands=image.bandNames().getInfo())\n",
    "        print('Image downloaded and saved successfully!')\n",
    "    else:\n",
    "        print('Failed to download the image.')\n",
    "\n",
    "fusion = stacked_images.addBands(dem)\n",
    "\n",
    "# # Merge all masks with logical AND operation\n",
    "# band_names = fusion.bandNames().getInfo()\n",
    "# mask = fusion.select(band_names[0]).mask()\n",
    "# for band_name in band_names[1:]:\n",
    "#     mask = mask.And(fusion.select(band_name).mask())\n",
    "# band_names = plot.bandNames().getInfo()\n",
    "# for band_name in band_names:\n",
    "#     mask = mask.And(plot.select(band_name).mask())\n",
    "\n",
    "# # Apply the mask to both images\n",
    "# fusion = fusion.updateMask(mask)\n",
    "# plot = plot.updateMask(mask)\n",
    "\n",
    "fusion = fusion.clip(REGION)\n",
    "plot = plot.clip(REGION)\n",
    "\n",
    "# save_image\n",
    "save_image(fusion, '../data/interim/fusion.tif', scale=SCALE, crs=CRS)\n",
    "save_image(plot, '../data/interim/plot.tif', scale=SCALE, crs=CRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "EEException",
     "evalue": "Image.select: Pattern '0_B4_median' did not match any bands.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hofin\\mambaforge\\envs\\ltm\\Lib\\site-packages\\ee\\data.py:343\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49mexecute(num_retries\u001b[39m=\u001b[39;49mnum_retries)\n\u001b[0;32m    344\u001b[0m \u001b[39mexcept\u001b[39;00m googleapiclient\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mHttpError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\hofin\\mambaforge\\envs\\ltm\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m         logger\u001b[39m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hofin\\mambaforge\\envs\\ltm\\Lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[39mraise\u001b[39;00m HttpError(resp, content, uri\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json returned \"Image.select: Pattern '0_B4_median' did not match any bands.\". Details: \"Image.select: Pattern '0_B4_median' did not match any bands.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hofin\\Lokal\\GitHub\\leaf-type-mixture\\notebooks\\data_prep.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hofin/Lokal/GitHub/leaf-type-mixture/notebooks/data_prep.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m reduced_texture_measures \u001b[39m=\u001b[39m texture_measures\u001b[39m.\u001b[39mreduceRegion(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hofin/Lokal/GitHub/leaf-type-mixture/notebooks/data_prep.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     reducer\u001b[39m=\u001b[39mee\u001b[39m.\u001b[39mReducer\u001b[39m.\u001b[39mmean(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hofin/Lokal/GitHub/leaf-type-mixture/notebooks/data_prep.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     geometry\u001b[39m=\u001b[39mREGION,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hofin/Lokal/GitHub/leaf-type-mixture/notebooks/data_prep.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     scale\u001b[39m=\u001b[39mSCALE,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hofin/Lokal/GitHub/leaf-type-mixture/notebooks/data_prep.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     crs\u001b[39m=\u001b[39mCRS)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hofin/Lokal/GitHub/leaf-type-mixture/notebooks/data_prep.ipynb#X25sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Convert to dictionary\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hofin/Lokal/GitHub/leaf-type-mixture/notebooks/data_prep.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m reduced_texture_measures \u001b[39m=\u001b[39m reduced_texture_measures\u001b[39m.\u001b[39;49mgetInfo()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hofin/Lokal/GitHub/leaf-type-mixture/notebooks/data_prep.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m reduced_texture_measures\n",
      "File \u001b[1;32mc:\\Users\\hofin\\mambaforge\\envs\\ltm\\Lib\\site-packages\\ee\\computedobject.py:94\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetInfo\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     89\u001b[0m   \u001b[39m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m    The object can evaluate to anything.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m   \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39;49mcomputeValue(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\hofin\\mambaforge\\envs\\ltm\\Lib\\site-packages\\ee\\data.py:952\u001b[0m, in \u001b[0;36mcomputeValue\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    949\u001b[0m body \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mexpression\u001b[39m\u001b[39m'\u001b[39m: serializer\u001b[39m.\u001b[39mencode(obj, for_cloud_api\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)}\n\u001b[0;32m    950\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[1;32m--> 952\u001b[0m \u001b[39mreturn\u001b[39;00m _execute_cloud_call(\n\u001b[0;32m    953\u001b[0m     _get_cloud_projects()\n\u001b[0;32m    954\u001b[0m     \u001b[39m.\u001b[39;49mvalue()\n\u001b[0;32m    955\u001b[0m     \u001b[39m.\u001b[39;49mcompute(body\u001b[39m=\u001b[39;49mbody, project\u001b[39m=\u001b[39;49m_get_projects_path(), prettyPrint\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    956\u001b[0m )[\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\hofin\\mambaforge\\envs\\ltm\\Lib\\site-packages\\ee\\data.py:345\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    343\u001b[0m   \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39mexecute(num_retries\u001b[39m=\u001b[39mnum_retries)\n\u001b[0;32m    344\u001b[0m \u001b[39mexcept\u001b[39;00m googleapiclient\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mHttpError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 345\u001b[0m   \u001b[39mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[1;31mEEException\u001b[0m: Image.select: Pattern '0_B4_median' did not match any bands."
     ]
    }
   ],
   "source": [
    "# Convert the image to grayscale\n",
    "gray = stacked_images.select(['0_B4_median', '0_B3_median', '0_B2_median']).reduce(ee.Reducer.mean())  # reduce three bands to one\n",
    "gray = gray.toUint16()\n",
    "\n",
    "# Calculate the GLCM\n",
    "glcm = gray.glcmTexture(3)\n",
    "\n",
    "# Select the texture measures to export\n",
    "texture_measures = glcm.select(\n",
    "    ['mean_contrast', 'mean_diss', 'mean_shade', 'mean_asm', 'mean_prom'])\n",
    "\n",
    "# Reduce the texture measures by mean\n",
    "reduced_texture_measures = texture_measures.reduceRegion(\n",
    "    reducer=ee.Reducer.mean(),\n",
    "    geometry=REGION,\n",
    "    scale=SCALE,\n",
    "    crs=CRS)\n",
    "\n",
    "# Convert to dictionary\n",
    "reduced_texture_measures = reduced_texture_measures.getInfo()\n",
    "reduced_texture_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a map.\n",
    "lon, lat = REGION.centroid().getInfo()['coordinates']\n",
    "# lat, lon = 45.77, 4.855\n",
    "my_map = folium.Map(location=[lat, lon], zoom_start=15)\n",
    "\n",
    "# Define a method for displaying Earth Engine image tiles on a folium map.\n",
    "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
    "    \"\"\"Adds a method for displaying Earth Engine image tiles to folium map.\"\"\"\n",
    "    map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
    "    folium.raster_layers.TileLayer(\n",
    "        tiles=map_id_dict['tile_fetcher'].url_format,\n",
    "        attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "        name=name,\n",
    "        overlay=True,\n",
    "        control=True\n",
    "    ).add_to(self)\n",
    "\n",
    "# Add Earth Engine drawing method to folium.\n",
    "folium.Map.add_ee_layer = add_ee_layer\n",
    "\n",
    "# Add the stacked composites to the map.\n",
    "vis_params = {**VIS_PARAMS, 'bands': ['0_B4_median', '0_B3_median', '0_B2_median']}\n",
    "my_map.add_ee_layer(stacked_images, vis_params, 'Sentinel-2 Composite')\n",
    "\n",
    "# Get colors\n",
    "viridis_cmap = plt.get_cmap('viridis')\n",
    "colors = []\n",
    "for i in range(256):\n",
    "    r, g, b, a = (int(value * 255) for value in viridis_cmap(i))\n",
    "    colors.append(f'#{r:02X}{g:02X}{b:02X}')\n",
    "\n",
    "# Add the plot to the map.\n",
    "vis_params = {\n",
    "    'min': 0,'max': 1,\n",
    "    'palette': colors\n",
    "}\n",
    "my_map.add_ee_layer(plot, vis_params, 'Leaf Type Mixture')\n",
    "\n",
    "# Add a layer control panel to the map.\n",
    "my_map.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# Create a map.\n",
    "lat, lon = 47.9357, 12.66535\n",
    "my_map = folium.Map(location=[lat, lon], zoom_start=15)\n",
    "\n",
    "# Define a method for displaying Earth Engine image tiles on a folium map.\n",
    "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
    "    \"\"\"Adds a method for displaying Earth Engine image tiles to folium map.\"\"\"\n",
    "    map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
    "    folium.raster_layers.TileLayer(\n",
    "        tiles=map_id_dict['tile_fetcher'].url_format,\n",
    "        attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "        name=name,\n",
    "        overlay=True,\n",
    "        control=True\n",
    "    ).add_to(self)\n",
    "\n",
    "# Add Earth Engine drawing method to folium.\n",
    "folium.Map.add_ee_layer = add_ee_layer\n",
    "\n",
    "# Add the stacked composites to the map.\n",
    "dem = ee.Image('projects/leaf-type-mixture/assets/DEM')\n",
    "my_map.add_ee_layer(dem.multiply(100).toUint16().entropy(ee.Kernel.square(4)), {'min': 0, 'max': 10}, 'DEM')\n",
    "\n",
    "# Add a layer control panel to the map.\n",
    "my_map.add_child(folium.LayerControl())\n",
    "\n",
    "# Display the map.\n",
    "display(my_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
