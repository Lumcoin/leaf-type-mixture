{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html (preprocessing, hyperparameter optimization) and using bayesian-optimization for hyperparameter optimization. Pipelines are heavily used and saved using dill instead of pickle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Optuna - A Hyperparameter Optimization Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 0.30346329731474664\n"
     ]
    }
   ],
   "source": [
    "# Create a baseline composite from a Sentinel image with the average across 1 year\n",
    "from ltm.data import sentinel_composite, list_bands\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from ltm.features import load_raster, drop_nan_rows\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "X_path = \"../data/processed/hyperparameter_tuning/X.tif\"\n",
    "y_path = \"../data/processed/ground_truth/y.tif\"\n",
    "\n",
    "# Create the composite if it does not exist\n",
    "if not Path(X_path).exists():\n",
    "    # List all available Sentinel 2 Level-2A bands\n",
    "    bands = list_bands()\n",
    "    b_bands = [band for band in bands if band.startswith(\"B\")]\n",
    "\n",
    "    Path(X_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    sentinel_composite(\n",
    "        y_path_from=y_path,\n",
    "        X_path_to=X_path,\n",
    "        time_window=(datetime(2017, 4, 1), datetime(2018, 4, 1)),\n",
    "        sentinel_bands=b_bands,\n",
    "    )\n",
    "\n",
    "# Compare it to the baseline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = load_raster(X_path)\n",
    "y = load_raster(y_path)\n",
    "\n",
    "X = X.dropna(axis=1)\n",
    "X, y = drop_nan_rows(X, y)\n",
    "\n",
    "cv_result = cross_validate(RandomForestRegressor(n_jobs=-1, random_state=42), X, y, cv=5, scoring=rmse_scorer, n_jobs=-1)\n",
    "score = cv_result[\"test_score\"].mean()\n",
    "\n",
    "print(f\"Baseline RMSE: {-score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use('science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metric and load the data\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from ltm.features import load_raster, drop_nan_rows\n",
    "\n",
    "# Define the metric\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "\n",
    "# Load the data\n",
    "X_path = \"../data/processed/reducer_composites/X.tif\"\n",
    "y_path = \"../data/processed/ground_truth/y.tif\"\n",
    "X = load_raster(X_path)\n",
    "y = load_raster(y_path)\n",
    "\n",
    "# Remove NaN columns from X and drop rows with NaN in y\n",
    "X = X.dropna(axis=1)\n",
    "X, y = drop_nan_rows(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create save folder and wrapper functions\n",
    "from pathlib import Path\n",
    "\n",
    "save_folder = \"../models/\"\n",
    "Path(save_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def suggest_categorical(*args, **kwargs):\n",
    "    return \"suggest_categorical\", args, kwargs\n",
    "\n",
    "def suggest_discrete_uniform(*args, **kwargs):\n",
    "    return \"suggest_discrete_uniform\", args, kwargs\n",
    "\n",
    "def suggest_float(*args, **kwargs):\n",
    "    return \"suggest_float\", args, kwargs\n",
    "\n",
    "def suggest_int(*args, **kwargs):\n",
    "    return \"suggest_int\", args, kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skelm import ELMRegressor\n",
    "from ltm.models import hyperparam_search\n",
    "\n",
    "elm_default = ELMRegressor(random_state=42)\n",
    "search_space = [\n",
    "    suggest_float(\"alpha\", 1e-8, 1e5, log=True),\n",
    "    suggest_categorical(\"include_original_features\", [True, False]),\n",
    "    suggest_float(\"n_neurons\", 1, 1000),\n",
    "    suggest_categorical(\"ufunc\", [\"tanh\", \"sigm\", \"relu\", \"lin\"]),\n",
    "    suggest_float(\"density\", 0.01, 0.99),\n",
    "]\n",
    "\n",
    "elm_model, elm_study = hyperparam_search(\n",
    "    elm_default,\n",
    "    search_space,\n",
    "    X,\n",
    "    y,\n",
    "    rmse_scorer,\n",
    "    n_trials=500,\n",
    "    save_folder=save_folder,\n",
    "    random_state=42\n",
    ")\n",
    "elm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from ltm.models import hyperparam_search\n",
    "\n",
    "et_default = ExtraTreesRegressor(n_jobs=-1, random_state=42)\n",
    "search_space = [\n",
    "    suggest_int(\"n_estimators\", 1, 200),\n",
    "    suggest_float(\"min_impurity_decrease\", 1e-5, 0.5, log=True),\n",
    "    suggest_categorical(\"criterion\", [\"squared_error\", \"absolute_error\"]),\n",
    "]\n",
    "\n",
    "et_model, et_study = hyperparam_search(\n",
    "    et_default,\n",
    "    search_space,\n",
    "    X,\n",
    "    y,\n",
    "    rmse_scorer,\n",
    "    n_trials=100,\n",
    "    save_folder=save_folder,\n",
    "    random_state=42\n",
    ")\n",
    "et_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from ltm.models import hyperparam_search\n",
    "\n",
    "hgbr_default = HistGradientBoostingRegressor(random_state=42)\n",
    "search_space = [\n",
    "    suggest_int(\"max_iter\", 100, 1000),\n",
    "    suggest_float(\"learning_rate\", 0.001, 0.5, log=True),\n",
    "    suggest_int(\"max_leaf_nodes\", 2, 1000),\n",
    "    suggest_categorical(\"l2_regularization\", [0, 1e-10, 1e-5, 1e-3, 1e-1, 1]),\n",
    "]\n",
    "\n",
    "hgbr_model, hgbr_study = hyperparam_search(\n",
    "    hgbr_default,\n",
    "    search_space,\n",
    "    X,\n",
    "    y,\n",
    "    rmse_scorer,\n",
    "    n_trials=100,\n",
    "    save_folder=save_folder,\n",
    "    random_state=42\n",
    ")\n",
    "hgbr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbour\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from ltm.models import hyperparam_search\n",
    "\n",
    "knn_default = KNeighborsRegressor(n_jobs=-1)\n",
    "search_space = [\n",
    "    suggest_int(\"n_neighbors\", 1, 100),\n",
    "    suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n",
    "    suggest_categorical(\"algorithm\", [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]),\n",
    "]\n",
    "\n",
    "knn_model, knn_study = hyperparam_search(\n",
    "    knn_default,\n",
    "    search_space,\n",
    "    X,\n",
    "    y,\n",
    "    rmse_scorer,\n",
    "    n_trials=500,\n",
    "    save_folder=save_folder,\n",
    "    random_state=42\n",
    ")\n",
    "knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from ltm.models import hyperparam_search\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "rf_default = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "search_space = [\n",
    "    suggest_int(\"n_estimators\", 1, 200),\n",
    "    suggest_int(\"max_depth\", 1, 1000),\n",
    "    suggest_float(\"max_features\", 0.1, 1.0),\n",
    "    suggest_float(\"min_samples_split\", 1e-5, 0.5, log=True),\n",
    "    suggest_float(\"min_samples_leaf\", 1e-5, 0.5, log=True),\n",
    "    suggest_categorical(\"bootstrap\", [True, False]),\n",
    "    suggest_categorical(\"criterion\", [\"squared_error\", \"absolute_error\", \"poisson\", \"friedman_mse\"]),\n",
    "]\n",
    "\n",
    "rf_model, rf_study = hyperparam_search(\n",
    "    rf_default,\n",
    "    search_space,\n",
    "    X,\n",
    "    y,\n",
    "    rmse_scorer,\n",
    "    n_trials=100,\n",
    "    save_folder=save_folder,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Linear Regression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from ltm.models import hyperparam_search\n",
    "\n",
    "sgd_default = SGDRegressor(random_state=42)\n",
    "search_space = [\n",
    "    suggest_categorical(\"loss\", [\"squared_error\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"]),\n",
    "    suggest_float(\"alpha\", 1e-6, 1e5, log=True),\n",
    "    suggest_float(\"l1_ratio\", 0, 1),\n",
    "]\n",
    "\n",
    "sgd_model, sgd_study = hyperparam_search(\n",
    "    sgd_default,\n",
    "    search_space,\n",
    "    X,\n",
    "    y,\n",
    "    rmse_scorer,\n",
    "    n_trials=500,\n",
    "    save_folder=save_folder,\n",
    "    random_state=42\n",
    ")\n",
    "sgd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVR\n",
    "from ltm.models import hyperparam_search\n",
    "\n",
    "svr_default = SVR()\n",
    "search_space = [\n",
    "    suggest_float(\"C\", 1e-5, 1e5, log=True),\n",
    "    suggest_float(\"epsilon\", 1e-5, 1e5, log=True),\n",
    "    suggest_categorical(\"kernel\", [\"poly\", \"rbf\", \"sigmoid\"]),\n",
    "]\n",
    "\n",
    "svr_model, svr_study = hyperparam_search(\n",
    "    svr_default,\n",
    "    search_space,\n",
    "    X,\n",
    "    y,\n",
    "    rmse_scorer,\n",
    "    n_trials=500,\n",
    "    save_folder=save_folder,\n",
    "    random_state=42\n",
    ")\n",
    "svr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from ltm.models import hyperparam_search\n",
    "\n",
    "xgb_default = XGBRegressor(n_jobs=-1, random_state=42)\n",
    "search_space = [\n",
    "    suggest_int(\"n_estimators\", 10, 200),\n",
    "    suggest_int(\"max_depth\", 1, 20),\n",
    "    suggest_float(\"learning_rate\", 0.001, 0.5, log=True),\n",
    "    suggest_float(\"gamma\", 0, 0.5),\n",
    "    suggest_int(\"min_child_weight\", 1, 11),\n",
    "]\n",
    "\n",
    "xgb_model, xgb_study = hyperparam_search(\n",
    "    xgb_default,\n",
    "    search_space,\n",
    "    X,\n",
    "    y,\n",
    "    rmse_scorer,\n",
    "    n_trials=100,\n",
    "    save_folder=save_folder,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = \"../reports/hyperparameter_tuning.csv\"\n",
    "studies = [\n",
    "    elm_study,\n",
    "    et_study,\n",
    "    hgbr_study,\n",
    "    knn_study,\n",
    "    rf_study,\n",
    "    sgd_study,\n",
    "    svr_study,\n",
    "    xgb_study,\n",
    "]\n",
    "\n",
    "if not Path(csv_path).exists():\n",
    "    default_models = [\n",
    "        elm_default,\n",
    "        et_default,\n",
    "        hgbr_default,\n",
    "        knn_default,\n",
    "        rf_default,\n",
    "        sgd_default,\n",
    "        svr_default,\n",
    "        xgb_default,\n",
    "    ]\n",
    "    models = [\n",
    "        elm_model,\n",
    "        et_model,\n",
    "        hgbr_model,\n",
    "        knn_model,\n",
    "        rf_model,\n",
    "        sgd_model,\n",
    "        svr_model,\n",
    "        xgb_model\n",
    "    ]\n",
    "    max_scores = {\n",
    "        study.study_name: -study.best_value for study in studies\n",
    "    }\n",
    "\n",
    "    # Get the scores for default models\n",
    "    model_names = [model.__class__.__name__ for model in default_models]\n",
    "    scores = [-cross_validate(model, X, y, scoring=rmse_scorer, n_jobs=-1)[\"test_score\"].mean() for model in default_models]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Model\": model_names,\n",
    "        \"Default Score\": scores,\n",
    "        \"Best Score\": [max_scores[model_name] for model_name in model_names]\n",
    "    })\n",
    "    df.set_index(\"Model\", inplace=True)\n",
    "    df.to_csv(csv_path)\n",
    "else:\n",
    "    df = pd.read_csv(csv_path, index_col=\"Model\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"SVR\"][\"Default Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the hyperparam search scores during search with performance of baseline models as reference\n",
    "for study in studies:\n",
    "    trials = study.trials_dataframe()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(-trials['value'], label='Score')\n",
    "    plt.title(study.study_name)\n",
    "    plt.xlabel(\"Trial\")\n",
    "    plt.ylabel(\"RMSE Score\")\n",
    "    plt.axhline(df.loc[study.study_name][\"Best Score\"], color='g', linestyle='--', label='Best score')\n",
    "    plt.axhline(df.loc[study.study_name][\"Default Score\"], color='r', linestyle='--', label='Default score')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
