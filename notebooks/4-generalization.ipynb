{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "## Bar Plot of RMSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltm.features import load_raster\n",
    "from ltm.models import bands_from_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "report_path = \"../reports/generalization.csv\"\n",
    "\n",
    "if not Path(report_path).exists():\n",
    "    experiment_0_path = \"../data/processed/ground_truth/data_2A.tif\"\n",
    "    experiment_1_path = \"../data/processed/band_importance/data.tif\"\n",
    "    experiment_2_path = \"../data/processed/data.tif\"\n",
    "    target_path = \"../data/processed/target.tif\"\n",
    "\n",
    "    experiment_0 = load_raster(experiment_0_path)\n",
    "    experiment_1 = load_raster(experiment_1_path)\n",
    "    experiment_2 = load_raster(experiment_2_path)\n",
    "    target = load_raster(target_path)\n",
    "\n",
    "    sentinel_bands, index_bands = bands_from_importance(\n",
    "        \"../reports/band_importance.csv\"\n",
    "    )\n",
    "    bands = [f\"1 {band} mean\" for band in sentinel_bands + index_bands]\n",
    "    experiment_1 = experiment_1[bands]\n",
    "\n",
    "    mask = target.notna()\n",
    "    experiment_0 = experiment_0[mask]\n",
    "    experiment_1 = experiment_1[mask]\n",
    "    experiment_2 = experiment_2[mask]\n",
    "    target = target[mask]\n",
    "\n",
    "    dummy_data = np.zeros_like(target).reshape(-1, 1)\n",
    "    dummy = DummyRegressor(strategy=\"mean\")\n",
    "    scoring = \"neg_root_mean_squared_error\"\n",
    "    dummy_score = -cross_val_score(\n",
    "        dummy, dummy_data, target, scoring=scoring, n_jobs=-1\n",
    "    ).mean()\n",
    "\n",
    "    rf = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "    rmse_0 = -cross_val_score(\n",
    "        rf, experiment_0, target, scoring=scoring, n_jobs=-1\n",
    "    ).mean()\n",
    "    rmse_1 = -cross_val_score(\n",
    "        rf, experiment_1, target, scoring=scoring, n_jobs=-1\n",
    "    ).mean()\n",
    "    rmse_2 = -cross_val_score(\n",
    "        rf, experiment_2, target, scoring=scoring, n_jobs=-1\n",
    "    ).mean()\n",
    "    ht_df = pd.read_csv(\"../reports/hyperparameter_tuning.csv\")\n",
    "    rmse_3 = ht_df[\"Root Mean Squared Error\"].min()\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Experiment\": [\n",
    "                \"Dummy Regressor\",\n",
    "                \"Baseline\",\n",
    "                \"Band Importance\",\n",
    "                \"Compositing\",\n",
    "                \"Hyperparameter Tuning\",\n",
    "            ],\n",
    "            \"Root Mean Squared Error\": [dummy_score, rmse_0, rmse_1, rmse_2, rmse_3],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df.to_csv(report_path, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of RMSE of every experiment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(\"science\")\n",
    "\n",
    "plt.plot([0, 1, 2, 3], df[\"Root Mean Squared Error\"][1:], marker=\"o\")\n",
    "plt.axhline(df[\"Root Mean Squared Error\"][0], color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Experiment\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Generalization of Experiments\")\n",
    "plt.ylim(0, 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Generalization\n",
    "\n",
    "Plan: Predict on 2018 with regular model (fitted on 2017). Then notice that predictions are garbage -> train model on either 2017 and 2019 or 2017-2023 (without 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty target raster from shape with NaN outside of shape\n",
    "from ltm.data import shapefile2raster\n",
    "from pathlib import Path\n",
    "\n",
    "name = \"Freisinger Forst\"\n",
    "shapefile_path = f\"../data/raw/{name}/{name}.shp\"\n",
    "target_path = f\"../data/processed/generalization/{name}.tif\"\n",
    "year = 2018\n",
    "batch_size = 25  # 25 for Freisinger Forst, 100 for Peterfecking, 200 for Traunstein, None for Brunnstube\n",
    "\n",
    "Path(target_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "if not Path(target_path).exists():\n",
    "    shapefile2raster(\n",
    "        shapefile_path=shapefile_path,\n",
    "        raster_path=target_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for the target area\n",
    "from ltm.models import create_data\n",
    "\n",
    "stem = Path(target_path).stem\n",
    "data_folder = str(Path(target_path).parent / stem)\n",
    "create_data(year, target_path, data_folder, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with best model on new data\n",
    "import dill\n",
    "\n",
    "df = pd.read_csv(\"../reports/hyperparameter_tuning.csv\", index_col=0)\n",
    "best_model = df[\"Root Mean Squared Error\"].idxmin()\n",
    "\n",
    "with open(f\"../models/{best_model}.pkl\", \"rb\") as f:\n",
    "    model = dill.load(f)\n",
    "\n",
    "data_path = Path(data_folder) / f\"{year}/{stem}.tif\"\n",
    "data = load_raster(str(data_path))\n",
    "\n",
    "xgb_pred = model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltm.data import download_dlt_2018\n",
    "from rasterio.plot import show\n",
    "import rasterio\n",
    "\n",
    "download_dlt_2018(\"../data/processed/generalization/Freisinger Forst.tif\", \"tmp.tif\")\n",
    "\n",
    "with rasterio.open(\"tmp.tif\") as src:\n",
    "    show(src, interpolation=\"nearest\", cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltm.features import load_raster\n",
    "\n",
    "freising = load_raster(\"tmp.tif\")\n",
    "prediction = load_raster(\"../data/processed/generalization/Freisinger Forst.tif\")\n",
    "\n",
    "mask = prediction.notna() & freising.notna() & (freising != 240)\n",
    "freising = freising[mask]\n",
    "prediction = prediction[mask]\n",
    "\n",
    "# Plot the violin plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import scienceplots\n",
    "\n",
    "# plt.style.use(\"science\")\n",
    "\n",
    "ax = sns.violinplot(x=freising, y=prediction, inner=\"quart\")\n",
    "ax.set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for each year\n",
    "target_path = \"../data/processed/target.tif\"\n",
    "data_folder = \"../data/processed/generalization/data/\"\n",
    "years = [2017, 2018, 2019, 2020, 2021, 2022]  # , 2023]\n",
    "\n",
    "for year in tqdm(years, desc=\"Years\"):\n",
    "    create_data(year, target_path, data_folder)\n",
    "\n",
    "# Combine all data into one dataframe\n",
    "print(\"Combining data...\")\n",
    "total_data = pd.DataFrame()\n",
    "for year in tqdm(years, desc=\"Years\"):\n",
    "    stem = Path(data_folder).stem\n",
    "    data_path = Path(data_folder) / f\"{year}/{stem}.tif\"\n",
    "    data = load_raster(str(data_path))\n",
    "    total_data = pd.concat([total_data, data])\n",
    "\n",
    "# Create target data\n",
    "target = load_raster(target_path)\n",
    "total_target = pd.concat([target] * len(years))\n",
    "\n",
    "# Drop rows with NaN label\n",
    "data, target = (\n",
    "    total_data[total_target.notna()],\n",
    "    total_target[total_target.notna()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model on new data of the study area\n",
    "import dill\n",
    "from sklearn.base import clone\n",
    "\n",
    "df = pd.read_csv(\"../reports/hyperparameter_tuning.csv\", index_col=0)\n",
    "best_model = df[\"Root Mean Squared Error\"].idxmin()\n",
    "\n",
    "with open(f\"../models/{best_model}.pkl\", \"rb\") as f:\n",
    "    model = dill.load(f)\n",
    "\n",
    "# Clone model in case warm_start=True and fit on new data\n",
    "model = clone(model)\n",
    "model.fit(data, target)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-val predict on seen data\n",
    "\n",
    "# Prediction on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prediction by overwriting the shape raster\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "with rasterio.open(target_path) as src:\n",
    "    profile = src.profile\n",
    "    shape = src.read().shape\n",
    "    nan_mask = np.isnan(src.read())\n",
    "\n",
    "xgb_reshaped = xgb_pred.reshape(shape)\n",
    "\n",
    "with rasterio.open(target_path, \"w\", **profile) as dst:\n",
    "    xgb_reshaped[nan_mask] = np.nan\n",
    "    dst.write(xgb_reshaped)\n",
    "    dst.descriptions = (\"Conifer Proportion\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use science style\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.style.use(\"science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "norm = Normalize(vmin=0, vmax=1)\n",
    "plt.imshow(\n",
    "    xgb_reshaped.transpose(1, 2, 0),\n",
    "    cmap=\"viridis\",\n",
    "    norm=norm,\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "plt.colorbar(shrink=0.8)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "ax = sns.kdeplot(xgb_reshaped.flatten())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
