{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "from slc.data import compute_target\n",
    "from slc.features import genera2target, load_raster\n",
    "\n",
    "\n",
    "def _genera2target_raster(path: Path, new_path: Path) -> None:\n",
    "    target = load_raster(path, monochrome_as_dataframe=True)\n",
    "    target = genera2target(target)\n",
    "    target = target.map({\"deciduous\": 0, \"evergreen\": 1})\n",
    "    target = target.to_numpy()\n",
    "\n",
    "    # Read profile and raster params\n",
    "    with rasterio.open(path) as src:\n",
    "        profile = src.profile\n",
    "        nan_mask = np.isnan(src.read()).all(axis=0)\n",
    "        nan_mask = np.expand_dims(nan_mask, axis=0)\n",
    "\n",
    "    shape = nan_mask.shape\n",
    "    profile[\"count\"] = shape[0]\n",
    "\n",
    "    # Write prediction to target raster\n",
    "    shutil.copy(path, new_path)\n",
    "    with rasterio.open(new_path, \"w\", **profile) as dst:\n",
    "        reshaped = target.reshape(shape).astype(float)\n",
    "        dst.write(reshaped)\n",
    "        dst.descriptions = (\"Evergreen\",)\n",
    "\n",
    "\n",
    "target_path = Path(\"../data/processed/generalization/traunstein_target.tif\")\n",
    "binary_path = target_path.parent / \"traunstein_binary.tif\"\n",
    "target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not target_path.exists():\n",
    "    plot = pd.read_csv(\"../data/interim/test/traunstein.csv\")\n",
    "\n",
    "    compute_target(target_path, plot)\n",
    "    _genera2target_raster(target_path, new_path=binary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scienceplots  # noqa: F401\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"science\")\n",
    "\n",
    "# Plot all recording dates\n",
    "ax = sns.kdeplot(\n",
    "    pd.read_csv(\"../data/interim/test/traunstein.csv\")[\"date\"].astype(\"datetime64[ns]\")\n",
    ")\n",
    "ax.set_title(\"Recording Dates\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ground truth\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import viridis\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Prepare the colormap\n",
    "cmap = mpl.cm.viridis\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "mappable = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "# Create subplot and colorbar\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Load the target raster\n",
    "with rasterio.open(binary_path) as src:\n",
    "    target_raster = src.read()\n",
    "\n",
    "# Plot the target raster\n",
    "ax.imshow(\n",
    "    target_raster.transpose(1, 2, 0),\n",
    "    interpolation=\"nearest\",\n",
    "    cmap=cmap,\n",
    "    norm=norm,\n",
    ")\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Ground Truth\")\n",
    "\n",
    "ax.legend(\n",
    "    handles=[\n",
    "        Patch(facecolor=viridis.get_over(), label=\"Evergreen\"),\n",
    "        Patch(facecolor=viridis.get_under(), label=\"Deciduous\"),\n",
    "    ],\n",
    "    title=\"Leaf Type\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "Path(\"../reports/figures/generalization\").mkdir(parents=True, exist_ok=True)\n",
    "figure_path = f\"../reports/figures/generalization/{ax.get_title()}.svg\"\n",
    "plt.savefig(figure_path, dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute data\n",
    "from slc.models import create_data\n",
    "\n",
    "data_folder = Path(\"../data/processed/generalization/traunstein_data/\")\n",
    "year = 2018\n",
    "data_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_path = data_folder / f\"{year}/data.tif\"\n",
    "\n",
    "if not data_path.exists():\n",
    "    create_data(\n",
    "        year=year,\n",
    "        target_path=target_path,\n",
    "        data_folder=data_folder,\n",
    "        top_n=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "tuning_df = pd.read_csv(\"../reports/hyperparameter_tuning.csv\", index_col=0)\n",
    "model_paths = [Path(f\"../models/{model}.pkl\") for model in tuning_df.index]\n",
    "\n",
    "tuned_models = []\n",
    "for model_path in model_paths:\n",
    "    with model_path.open(\"rb\") as file:\n",
    "        model = dill.load(file)  # noqa: S301\n",
    "        tuned_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model_folder = Path(\"../data/processed/generalization/\")\n",
    "model_folder.mkdir(parents=True, exist_ok=True)\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 3))\n",
    "\n",
    "prediction_rasters = []\n",
    "for ax, model in tqdm(list(zip(axs.flatten(), tuned_models, strict=False))):\n",
    "    path = model_folder / f\"{model.steps[-1][1].__class__.__name__}.tif\"\n",
    "    if Path(path).exists():\n",
    "        with rasterio.open(path) as src:\n",
    "            prediction_raster = src.read()\n",
    "    else:\n",
    "        Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        data = load_raster(data_path, monochrome_as_dataframe=True)\n",
    "        prediction_raster = model.predict(data)\n",
    "        with rasterio.open(binary_path) as src:\n",
    "            profile = src.profile\n",
    "            shape = src.read().shape\n",
    "            nan_or_larix = np.isnan(src.read())\n",
    "\n",
    "        prediction_raster = prediction_raster.reshape(shape).astype(float)\n",
    "        prediction_raster[nan_or_larix] = np.nan\n",
    "\n",
    "        with rasterio.open(path, \"w\", **profile) as dst:\n",
    "            dst.write(prediction_raster)\n",
    "\n",
    "    prediction_rasters.append(prediction_raster)\n",
    "\n",
    "    im = ax.imshow(\n",
    "        prediction_raster.transpose(1, 2, 0),\n",
    "        interpolation=\"nearest\",\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "    )\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(model.steps[-1][1].__class__.__name__)\n",
    "\n",
    "fig.legend(\n",
    "    handles=[\n",
    "        Patch(facecolor=viridis.get_over(), label=\"Evergreen\"),\n",
    "        Patch(facecolor=viridis.get_under(), label=\"Deciduous\"),\n",
    "    ],\n",
    "    title=\"Leaf Type\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "\n",
    "figure_path = \"../reports/figures/hyperparameter_tuning/Predictions.svg\"\n",
    "plt.savefig(figure_path, dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def _rolling_window(\n",
    "    x: pd.Series,\n",
    "    data: pd.DataFrame,\n",
    "    window_width: float,\n",
    "    function: Callable,\n",
    "    n_samples: int = 100,\n",
    ") -> pd.DataFrame:\n",
    "    min_sample_size = 2\n",
    "    if n_samples < min_sample_size:\n",
    "        msg = \"n_samples must be at least 2\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    x = x.reset_index(drop=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    idcs = x.argsort()\n",
    "    sorted_x = x[idcs]\n",
    "    data = data.loc[idcs]\n",
    "\n",
    "    x_values = []\n",
    "    results = []\n",
    "    for x_value in np.linspace(sorted_x.min(), sorted_x.max(), n_samples):\n",
    "        mask = sorted_x.between(x_value - window_width / 2, x_value + window_width / 2)\n",
    "        data_window = data[mask]\n",
    "        result = function(data_window)\n",
    "        x_values.append(x_value)\n",
    "        results.append(result)\n",
    "\n",
    "    return pd.DataFrame(results, index=x_values)\n",
    "\n",
    "\n",
    "def _f1_stats(data: pd.DataFrame) -> dict:\n",
    "    target = data[\"Target\"].to_numpy()\n",
    "    prediction = data[\"Prediction\"].to_numpy()\n",
    "\n",
    "    point_estimate = f1_score(target, prediction)\n",
    "\n",
    "    n_resamples = 1000\n",
    "    alpha = 0.95\n",
    "    index = np.arange(target.size)\n",
    "    resamples = np.random.default_rng().choice(\n",
    "        index, size=(n_resamples, index.size), replace=True\n",
    "    )\n",
    "\n",
    "    # Vectorized computation of resampled F1 scores\n",
    "    resampled_f1s = np.array(\n",
    "        [f1_score(target[resample], prediction[resample]) for resample in resamples]\n",
    "    )\n",
    "\n",
    "    lower_bound, upper_bound = np.percentile(\n",
    "        resampled_f1s, [(1 - alpha) / 2 * 100, (1 + alpha) / 2 * 100]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"Point Estimate\": point_estimate,\n",
    "        \"Lower Bound\": lower_bound,\n",
    "        \"Upper Bound\": upper_bound,\n",
    "    }\n",
    "\n",
    "\n",
    "best_idx = tuning_df[\"F1 Score\"].argmax()\n",
    "best_model = tuned_models[best_idx].steps[-1][1].__class__.__name__\n",
    "\n",
    "dem = load_raster(\"../data/external/dem_median.tif\")\n",
    "target = load_raster(\"../data/processed/generalization/traunstein_binary.tif\")\n",
    "prediction = load_raster(f\"../data/processed/generalization/{best_model}.tif\")\n",
    "\n",
    "data = pd.DataFrame({\"Target\": target, \"Prediction\": prediction})\n",
    "\n",
    "mask = target.notna()\n",
    "dem = dem[mask]\n",
    "data = data[mask]\n",
    "\n",
    "result_path = Path(\"../reports/rolling_window.csv\")\n",
    "if not result_path.exists():\n",
    "    result = _rolling_window(\n",
    "        dem, data, window_width=5, function=_f1_stats, n_samples=200\n",
    "    )\n",
    "    result.to_csv(result_path)\n",
    "else:\n",
    "    result = pd.read_csv(result_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = result.index\n",
    "point_estimate = result[\"Point Estimate\"]  # .rolling(window=10).mean()\n",
    "lower_bound = result[\"Lower Bound\"]  # .rolling(window=10).mean()\n",
    "upper_bound = result[\"Upper Bound\"]  # .rolling(window=10).mean()\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.plot(x, point_estimate, linewidth=2)\n",
    "ax.fill_between(x, lower_bound, upper_bound, color=\"b\", alpha=0.1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel(\"Tree Height (m)\")\n",
    "ax.set_ylabel(\"F1 Score\")\n",
    "ax.set_title(\"F1 Score increases with Height\")\n",
    "ax.legend([\"Point Estimate\", \"95% Confidence Interval\"])\n",
    "\n",
    "figure_path = f\"../reports/figures/hyperparameter_tuning/{ax.get_title()}.svg\"\n",
    "plt.savefig(figure_path, dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the percentage of endmembers across the height of the trees\n",
    "from slc.features import load_raster\n",
    "\n",
    "window_size = 200\n",
    "\n",
    "target = load_raster(\"../data/processed/generalization/traunstein_target.tif\")\n",
    "regression_target = genera2target(target, regression=True).copy()\n",
    "regression_target[\"evergreen proportion\"] = regression_target[\n",
    "    \"evergreen\"\n",
    "] / regression_target.sum(axis=1)\n",
    "\n",
    "dem = load_raster(\"../data/external/dem_median.tif\")\n",
    "\n",
    "target_df = regression_target[\n",
    "    \"evergreen proportion\"\n",
    "].copy()  # pd.Series(target_raster.flatten())\n",
    "prediction_df = pd.Series(prediction_rasters[best_idx].flatten())\n",
    "dem_df = pd.Series(dem.values)\n",
    "\n",
    "mask = target_df.notna()\n",
    "target_df, prediction_df, dem_df = target_df[mask], prediction_df[mask], dem_df[mask]\n",
    "\n",
    "# TODO@peter: Note somewhere that endmember if +- 5% of 0 or 1\n",
    "em_margin = 0.05\n",
    "endmembers = ((target_df > em_margin) & (target_df < 1 - em_margin)).astype(int)\n",
    "\n",
    "dem_df = dem_df.reset_index(drop=True)\n",
    "endmembers = endmembers.reset_index(drop=True)\n",
    "indices = dem_df.argsort()\n",
    "endmembers, dem_df = endmembers[indices], dem_df[indices]\n",
    "moving_average = endmembers.rolling(window_size).mean()\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.fill_between(dem_df, 0, 1 - moving_average, color=\"b\", alpha=0.1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel(\"Tree Height (m)\")\n",
    "ax.set_ylabel(\"Pure pixels proportion\")\n",
    "ax.set_title(\"Pure Pixel Proportion by Height\")\n",
    "\n",
    "figure_path = f\"../reports/figures/hyperparameter_tuning/{ax.get_title()}.svg\"\n",
    "plt.savefig(figure_path, dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on new data with the best model\n",
    "from typing import IO\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from matplotlib.cm import viridis\n",
    "from matplotlib.patches import Patch\n",
    "from rasterio.plot import show\n",
    "\n",
    "\n",
    "def _plot_src(\n",
    "    src: IO,\n",
    "    title: str | None = None,\n",
    "    contains_larix: pd.Series | None = None,\n",
    "    *,\n",
    "    alternative_dlt: bool = False,\n",
    ") -> None:\n",
    "    if contains_larix is not None:\n",
    "        src = src.read()\n",
    "        larix_raster = contains_larix.to_numpy().reshape(src.shape[1:])\n",
    "        src[:, larix_raster] = np.nan\n",
    "\n",
    "    ax = plt.subplot()\n",
    "    ax = show(src, interpolation=\"nearest\", ax=ax)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    handles = [\n",
    "        Patch(facecolor=viridis.get_over(), label=\"Conifer\"),\n",
    "        Patch(facecolor=viridis.get_under(), label=\"Broadleaf\"),\n",
    "    ]\n",
    "    if alternative_dlt:\n",
    "        handles = [\n",
    "            Patch(facecolor=viridis.get_over(), label=\"Evergreen\"),\n",
    "            Patch(facecolor=viridis.get_under(), label=\"Deciduous\"),\n",
    "        ]\n",
    "\n",
    "    ax.legend(\n",
    "        handles=handles,\n",
    "        title=\"Leaf Type\",\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(1, 0.5),\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dem_path = Path(\"../data/external/dem_median.tif\")\n",
    "with rasterio.open(dem_path) as src:\n",
    "    ax = plt.subplot()\n",
    "    show(src, interpolation=\"nearest\", ax=ax)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "contains_larix = load_raster(target_path)[\"Larix\"] > 0\n",
    "with rasterio.open(binary_path) as src:\n",
    "    _plot_src(\n",
    "        src,\n",
    "        title=\"Traunstein Forest Dynamics Plot\",\n",
    "        alternative_dlt=True,\n",
    "        contains_larix=contains_larix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuned_models[best_idx].steps[-1][1].__class__.__name__\n",
    "prediction_path = model_folder / f\"{best_model}.tif\"\n",
    "with rasterio.open(prediction_path) as src:\n",
    "    _plot_src(\n",
    "        src,\n",
    "        title=f\"Prediction - {best_model}\",\n",
    "        alternative_dlt=True,\n",
    "        contains_larix=contains_larix,\n",
    "    )\n",
    "\n",
    "    nan_or_larix = np.isnan(src.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slc.data import download_dlt_2018\n",
    "from slc.features import genera2target\n",
    "\n",
    "dlt_2018_path = Path(\"../data/external/dlt_2018.tif\")\n",
    "download_dlt_2018(binary_path, dlt_2018_path, use_mask=True)\n",
    "\n",
    "with rasterio.open(dlt_2018_path) as src:\n",
    "    _plot_src(src, title=\"DLT 2018\", contains_larix=contains_larix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare our approach with DLT 2018 for each metric\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "def _compare_with_dlt_2018(\n",
    "    binary_path: Path, prediction_path: Path, dlt_path: Path, contains_larix: pd.Series\n",
    ") -> dict:\n",
    "    # TODO: mask all pixels containing larix\n",
    "    with rasterio.open(binary_path) as src:\n",
    "        target = src.read(1)\n",
    "        shape = target.shape\n",
    "        contains_larix = contains_larix.to_numpy().reshape(shape)\n",
    "\n",
    "    with rasterio.open(prediction_path) as src:\n",
    "        prediction = src.read(1)\n",
    "\n",
    "    # TODO: evergreen_larix=True to compare it 1:1 with DLT 2018\n",
    "    with rasterio.open(dlt_path) as src:\n",
    "        dlt = src.read(1)\n",
    "\n",
    "    # Mask out NaN values and pixels containing Larix\n",
    "    nan_or_larix = (\n",
    "        np.isnan(target) | np.isnan(prediction) | np.isnan(dlt) | contains_larix\n",
    "    )\n",
    "    target = target[~nan_or_larix]\n",
    "    prediction = prediction[~nan_or_larix]\n",
    "    dlt = dlt[~nan_or_larix]\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(target, prediction)\n",
    "    f1 = f1_score(target, prediction, average=\"weighted\")\n",
    "    kappa = cohen_kappa_score(target, prediction)\n",
    "    cm = confusion_matrix(target, prediction)\n",
    "\n",
    "    dlt_accuracy = accuracy_score(target, dlt)\n",
    "    dlt_f1 = f1_score(target, dlt, average=\"weighted\")\n",
    "    dlt_kappa = cohen_kappa_score(target, dlt)\n",
    "    dlt_cm = confusion_matrix(target, dlt)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"kappa\": kappa,\n",
    "        \"cm\": cm,\n",
    "        \"dlt_accuracy\": dlt_accuracy,\n",
    "        \"dlt_f1\": dlt_f1,\n",
    "        \"dlt_kappa\": dlt_kappa,\n",
    "        \"dlt_cm\": dlt_cm,\n",
    "    }\n",
    "\n",
    "\n",
    "metrics = _compare_with_dlt_2018(\n",
    "    binary_path, prediction_path, dlt_2018_path, contains_larix\n",
    ")\n",
    "\n",
    "cm = metrics[\"cm\"]\n",
    "dlt_cm = metrics[\"dlt_cm\"]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "display_labels = [\"Deciduous\", \"Evergreen\"]\n",
    "ConfusionMatrixDisplay(cm, display_labels=display_labels).plot(\n",
    "    ax=axs[0], cmap=\"viridis\"\n",
    ")\n",
    "axs[0].set_title(\"Confusion Matrix\")\n",
    "axs[0].set_xlabel(\"Predicted\")\n",
    "axs[0].set_ylabel(\"True\")\n",
    "\n",
    "display_labels = [\"Broadleaf\", \"Conifer\"]\n",
    "ConfusionMatrixDisplay(dlt_cm, display_labels=display_labels).plot(\n",
    "    ax=axs[1], cmap=\"viridis\"\n",
    ")\n",
    "axs[1].set_title(\"DLT 2018 Confusion Matrix\")\n",
    "axs[1].set_xlabel(\"Predicted\")\n",
    "axs[1].set_ylabel(\"True\")\n",
    "\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
