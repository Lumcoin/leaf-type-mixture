{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import seaborn as sns\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import pearsonr, randint, spearmanr, uniform\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import (make_scorer, max_error, mean_squared_error,\n",
    "                             median_absolute_error)\n",
    "from sklearn.model_selection import (BaseCrossValidator, GridSearchCV, KFold,\n",
    "                                     RandomizedSearchCV)\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(image, annotation):\n",
    "    # Load dataset image\n",
    "    with rasterio.open(image) as src:\n",
    "        raster = src.read()\n",
    "        bands = src.count\n",
    "        labels = src.descriptions\n",
    "        X = raster.transpose(1, 2, 0).reshape(-1, bands)\n",
    "\n",
    "    # Load annotation\n",
    "    with rasterio.open(annotation) as src:\n",
    "        y = src.read(1).flatten()\n",
    "\n",
    "    # remove nan values\n",
    "    mask = ~np.isnan(X).any(axis=1)\n",
    "    mask = np.logical_and(mask, ~np.isnan(y))\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    # prettify labels\n",
    "    pretty_labels = []\n",
    "    for label in labels:\n",
    "        label = label.replace('_', ' ')\n",
    "        pretty_label = ' '.join([word[0].upper() + word[1:]\n",
    "                                 for word in label.split()])\n",
    "        pretty_labels.append(pretty_label)\n",
    "\n",
    "    return X, y, labels\n",
    "\n",
    "class EndMemberSplitter(BaseCrossValidator):\n",
    "    def __init__(self, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "        self.k_fold = KFold(n_splits=n_splits)\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        for train, test in self.k_fold.split(X, y):\n",
    "            end_member_train = np.where((y[train] == 0)\n",
    "                                        | (y[train] == 1))[0]\n",
    "            yield end_member_train, test\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "\n",
    "# Load the dataset\n",
    "X, y, labels = load_dataset('fusion.tif', 'plot.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(X, method='spearman'):\n",
    "    if method == 'spearman':\n",
    "        similarity = spearmanr(X).correlation\n",
    "    elif method == 'pearson':\n",
    "        similarity = pearsonr(X).correlation\n",
    "    elif method == 'mutual_info':\n",
    "        similarity = np.full((X.shape[1], X.shape[1]), np.nan)\n",
    "        for i, band_1 in tqdm(enumerate(X.T)):\n",
    "            if band_1.std() == 0: continue\n",
    "            for j, band_2 in enumerate(X.T):\n",
    "                if band_2.std() == 0: continue\n",
    "                similarity[i, j] = mutual_info_regression(band_1.reshape(-1, 1),\n",
    "                                                          band_2)[0]\n",
    "    else:\n",
    "        raise ValueError(f'Unknown method: \"{method}\"')\n",
    "    \n",
    "    # Ensure the correlation matrix is normalized and symmetric\n",
    "    np.fill_diagonal(similarity, 0)\n",
    "    similarity /= np.nanmax(similarity)\n",
    "    similarity = (similarity + similarity.T) / 2\n",
    "    similarity[np.isnan(similarity)] = 1\n",
    "    np.fill_diagonal(similarity, 1)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "def plot_dendrogram(similarity_matrix, labels):\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    distance_matrix = 1 - np.abs(similarity_matrix)\n",
    "    dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "    dendro = hierarchy.dendrogram(\n",
    "        dist_linkage, labels=labels, ax=ax, leaf_rotation=90\n",
    "    )\n",
    "\n",
    "    return dendro\n",
    "\n",
    "def hierarchial_dim_red(X, labels, similarity_matrix, threshold=0.2):\n",
    "    distance_matrix = 1 - np.abs(similarity_matrix)\n",
    "    dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "\n",
    "    cluster_ids = hierarchy.fcluster(dist_linkage, threshold, criterion=\"distance\")\n",
    "    cluster_id_to_feature_ids = defaultdict(list)\n",
    "    for idx, cluster_id in enumerate(cluster_ids):\n",
    "        cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "    \n",
    "    selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "        \n",
    "    return X[:, selected_features], [labels[i] for i in selected_features]\n",
    "\n",
    "def pairplot(X, labels, similar_labels):\n",
    "    similar_indices = [labels.index(label) for label in similar_labels]\n",
    "    similar_df = pd.DataFrame(X[:, similar_indices], columns=similar_labels)\n",
    "\n",
    "    sns.pairplot(similar_df)\n",
    "\n",
    "def get_similar_labels(similarity_matrix, labels, num_labels=None, reversed=False, ignore_ones=False):\n",
    "    # TODO: remove columns with NaN from result if \"ignore_ones\", as it suggest high importance for those\n",
    "    similarity_matrix = similarity_matrix.copy()\n",
    "\n",
    "    # Fill lower triangle with NaNs\n",
    "    similarity_matrix[np.tril_indices(similarity_matrix.shape[0], -1)] = np.nan\n",
    "\n",
    "    # Replace 1s with NaNs if requested\n",
    "    if ignore_ones:\n",
    "        similarity_matrix[similarity_matrix == 1] = np.nan\n",
    "    corr_matrix = pd.DataFrame(similarity_matrix, columns=labels, index=labels)\n",
    "\n",
    "    # Sort by correlation\n",
    "    corr_matrix = corr_matrix.abs()\n",
    "    corr_matrix = corr_matrix.unstack()\n",
    "    corr_matrix = corr_matrix.sort_values(ascending=reversed)\n",
    "    print('Most similar pairs:')\n",
    "    print(corr_matrix.head(num_labels))\n",
    "    corr_pairs = corr_matrix.index\n",
    "\n",
    "    corr_columns = []\n",
    "    redundant_columns = (num for tup in corr_pairs for num in tup)  # flatten\n",
    "    for column in redundant_columns:\n",
    "        if column not in corr_columns:\n",
    "            corr_columns.append(column)\n",
    "            if num_labels is not None and len(corr_columns) >= num_labels:\n",
    "                break\n",
    "\n",
    "    return corr_columns\n",
    "\n",
    "# Draw interesting plots\n",
    "similarity = similarity_matrix(X, method='spearman')#  'mutual_info')#  \n",
    "plt.imshow(similarity)\n",
    "plot_dendrogram(similarity, labels)\n",
    "similar_labels = get_similar_labels(similarity, labels, num_labels=5, ignore_ones=True)\n",
    "pairplot(X, labels, similar_labels)\n",
    "\n",
    "# Dimensionality reduction\n",
    "# X, labels = hierarchial_dim_red(X, labels, similarity, threshold=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics\n",
    "metrics = {'max_error': max_error,\n",
    "           'median_absolute_error': median_absolute_error,\n",
    "           'mean_squared_error': mean_squared_error}\n",
    "refit = 'mean_squared_error'  # metric for best model selection\n",
    "\n",
    "# Define the models and hyperparameter search space\n",
    "# Possible distributions: expon, gamma, uniform, loguniform or randint\n",
    "# Random state will be set by sklearn, if scipy >= 0.16 is available\n",
    "models = {\n",
    "    XGBRegressor(): {\n",
    "        'n_estimators': randint(10, 100-10),\n",
    "        'max_depth': randint(1, 20),\n",
    "        # 'learning_rate': uniform(0.01, 0.5),\n",
    "        # 'gamma': uniform(0, 0.5),\n",
    "        # 'min_child_weight': randint(1, 11),\n",
    "    },\n",
    "    RandomForestRegressor(): {\n",
    "        'n_estimators': randint(1, 100-1),\n",
    "        'max_depth': randint(1, 20),\n",
    "        'max_features': randint(1, 11),\n",
    "        'min_samples_split': randint(1, 11),\n",
    "        'min_samples_leaf': randint(1, 11),\n",
    "        'bootstrap': [True, False],\n",
    "        # 'criterion': ['squared_error', 'absolute_error'  'friedman_mse', 'poisson'],\n",
    "    },\n",
    "    ExtraTreesRegressor(): {\n",
    "        'n_estimators': randint(1, 100-1),\n",
    "        'min_impurity_decrease': uniform(0, 0.5),\n",
    "        'criterion': ['squared_error', 'absolute_error'],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define the search strategy\n",
    "search = RandomizedSearchCV# GridSearchCV#  \n",
    "cv = EndMemberSplitter(n_splits=5)#  KFold(n_splits=5)#  \n",
    "search_kwargs = dict(cv=EndMemberSplitter(5), return_train_score=True, n_iter=100, verbose=1, random_state=0)  # , n_jobs=-1\n",
    "\n",
    "# Perform hyperparameter optimization using the defined search\n",
    "scorers = {metric_name: make_scorer(metric, greater_is_better=False) for metric_name, metric in metrics.items()}\n",
    "best_models = []\n",
    "cv_results = []\n",
    "for model, param_distributions in models.items():\n",
    "    current_search = search(model, param_distributions, \n",
    "                               scoring=scorers, refit=refit, **search_kwargs)\n",
    "    current_search.fit(X, y)\n",
    "\n",
    "    best_models.append(current_search.best_estimator_)\n",
    "    cv_results.append(current_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set colors for plotting\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "# Plot the results for each parameter of each model\n",
    "for results, (model, param_distributions) in zip(cv_results, models.items()):\n",
    "    for parameter in param_distributions.keys():\n",
    "        # Skip if parameter is not convertible to float\n",
    "        try:\n",
    "            X_axis = np.array(results[f\"param_{parameter}\"].data, dtype=float)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        # Setup plot\n",
    "        plt.figure(figsize=(13, 13))\n",
    "        ax = plt.subplot()\n",
    "        ax.set_xlabel(parameter)\n",
    "        ax.set_ylabel(\"score\")\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        # Sort results by parameter value\n",
    "        sort_idx = np.argsort(X_axis)\n",
    "        X_axis = X_axis[sort_idx]\n",
    "        results = {key: np.array(value)[sort_idx] for key, value in results.items()}\n",
    "\n",
    "        # Plot the different metrics\n",
    "        for (metric_name, scorer), color in zip(scorers.items(), colors):\n",
    "            for sample, style in ((\"train\", \"--\"), (\"test\", \"-\")):\n",
    "                sample_score_mean = results[f\"mean_{sample}_{metric_name}\"] * scorer._sign\n",
    "                sample_score_std = results[f\"std_{sample}_{metric_name}\"]\n",
    "                ax.fill_between(\n",
    "                    X_axis,\n",
    "                    sample_score_mean - sample_score_std,\n",
    "                    sample_score_mean + sample_score_std,\n",
    "                    alpha=0.1 if sample == \"test\" else 0,\n",
    "                    color=color,\n",
    "                )\n",
    "                ax.plot(\n",
    "                    X_axis,\n",
    "                    sample_score_mean,\n",
    "                    style,\n",
    "                    color=color,\n",
    "                    label=f\"{metric_name} ({sample})\",\n",
    "                )\n",
    "\n",
    "            # Find best score\n",
    "            best_index = np.nonzero(results[f\"rank_test_{metric_name}\"] == 1)[0][0]\n",
    "            best_score = results[f\"mean_test_{metric_name}\"][best_index] * scorer._sign\n",
    "\n",
    "            # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "            ax.plot(\n",
    "                [X_axis[best_index]] * 2,\n",
    "                [0, best_score],\n",
    "                linestyle=\":\",\n",
    "                color=color,\n",
    "                marker=\"x\",\n",
    "                markeredgewidth=3,\n",
    "                ms=8,\n",
    "            )\n",
    "\n",
    "            # Annotate the best score for that scorer\n",
    "            ax.annotate(\"%0.2f\" % best_score, (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "            # Show legend with metrics and test/train\n",
    "            ax.legend(loc=\"best\")\n",
    "        \n",
    "        # Show plot\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
